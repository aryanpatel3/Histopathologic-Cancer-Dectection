{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Histopathologic Cancer Dectection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanpatel3/Histopathologic-Cancer-Dectection/blob/master/Histopathologic_Cancer_Dectection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpJWCo0ZgPKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4TX2VD2GCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3yhZnFkgKkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGr0GR6FgL1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI_D4_bCgfAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "import keras.layers\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBuMwir3giGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (96, 96, 3), activation = 'relu'))\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "# Compiling the CNN\n",
        "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WgjHoqKis4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/DataSets/HCD_Data/train_labels.csv')\n",
        "\n",
        "file_names = list(dataset['id'].values)\n",
        "img_labels = list(dataset['label'].values)\n",
        "\n",
        "print(file_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrsq5uQxVZ8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, os.path\n",
        "\n",
        "val_image_list = []\n",
        "path = \"/content/drive/My Drive/DataSets/HCD_Data/validation\"\n",
        "\n",
        "for f in os.listdir(path):\n",
        "  f = f.replace('.tif', '')\n",
        "  val_image_list.append(f)\n",
        "  \n",
        "print(val_image_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Ic4TYngmAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/DataSets/HCD_Data/train', target_size = (96, 96), batch_size = 32, class_mode = 'binary')\n",
        "validation_set = train_datagen.flow_from_directory('/content/drive/My Drive/DataSets/HCD_Data/validation', target_size = (96, 96), batch_size = 32, class_mode = 'binary')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/DataSets/HCD_Data/test', target_size = (96, 96), batch_size = 32, class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJO4_OPHhgOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "steps_per_epoch = 50,\n",
        "epochs = 10,\n",
        "validation_data = validation_set,\n",
        "validation_steps = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w192bJHRhiF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 3 - Making new predictions\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "count = 0\n",
        "  \n",
        "for x in range(613):\n",
        "  test_image = image.load_img(image_list[x],target_size = (96, 96))\n",
        "  test_image = image.img_to_array(test_image)\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "  result = classifier.predict(test_image)\n",
        "  training_set.class_indices\n",
        "  if result[0][0] >= 0.5:\n",
        "    prediction = 'Atleast one cancerous cell present'\n",
        "    \n",
        "  else:\n",
        "    prediction = 'No cancerous cells present'\n",
        "    count += 1\n",
        "  #print(prediction)\n",
        "  #print(result[0][0])\n",
        "    \n",
        "print(\"correct = \" + str(count))\n",
        "print('acc = ' + str(count/613))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTUrI7W2023v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, os.path\n",
        "\n",
        "image_list = []\n",
        "path = \"/content/drive/My Drive/DataSets/HCD_Data/train/1/\"\n",
        "\n",
        "for f in os.listdir(path):\n",
        "  #f = f.replace('.tif', '')\n",
        "  image_list.append(os.path.join(path, f))\n",
        "  \n",
        "print(len(image_list))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MrUXkm_EDou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code to save a pickel file\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "# now you can save it to a file\n",
        "joblib.dump(classifier, 'HCD_keras.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRZwmjTuvabx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the training images into 2 subfolder depending on the label(0 and 1)\n",
        "for f in range(1500):\n",
        "  \n",
        "  pos = np.where(dataset['id'] == image_list[f])\n",
        "  pos = int(pos[0])\n",
        "  #print(pos)\n",
        "  \n",
        "  current_img = file_names[pos]\n",
        "  current_label = img_labels[pos]\n",
        "  \n",
        "  #print('current_img = ' + current_img)\n",
        "  shutil.move('/content/drive/My Drive/DataSets/HCD_Data/train/1/' + str(current_img) + '.tif', '/content/drive/My Drive/DataSets/HCD_Data/train/' + str(current_label) + '/' + current_img + '.tif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTBWt3cOWzNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in range(500):\n",
        "  \n",
        "  pos = np.where(dataset['id'] == val_image_list[f])\n",
        "  pos = int(pos[0])\n",
        "  \n",
        "  current_img = file_names[pos]\n",
        "  current_label = img_labels[pos]\n",
        "  \n",
        "  shutil.move('/content/drive/My Drive/DataSets/HCD_Data/validation/' + str(current_img) + '.tif', '/content/drive/My Drive/DataSets/HCD_Data/validation/' + str(current_label) + '/' + current_img + '.tif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f79xAdI6EnOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code to find a file\n",
        "import os\n",
        "\n",
        "def find(name, path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if name in files:\n",
        "            return os.path.join(root, name)\n",
        "        \n",
        "find('HCD_keras.pkl', '/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq7OGR78rJuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert any array values or something to strings\n",
        "def to_str(var):\n",
        "    return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]\n",
        "  \n",
        "#Find the row number where a picture with a certain name is located\n",
        "x = np.where(dataset['id'] ==  'pic_name\n",
        "\n",
        "x = int(x[0])\n",
        "\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Histopathologic Cancer Dectection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpJWCo0ZgPKu",
        "colab_type": "code",
        "outputId": "7658fe2b-50a3-4076-d428-1d1769d17657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.7)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.4.2)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4TX2VD2GCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3yhZnFkgKkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGr0GR6FgL1S",
        "colab_type": "code",
        "outputId": "aff47d6d-5160-4e92-f34d-523f10ba8a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI_D4_bCgfAU",
        "colab_type": "code",
        "outputId": "ea29cd20-e950-46f6-b04b-81b858c0cdb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "import keras.layers\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBuMwir3giGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (96, 96, 3), activation = 'relu'))\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "# Compiling the CNN\n",
        "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WgjHoqKis4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/DataSets/HCD_Data/train_labels.csv')\n",
        "\n",
        "file_names = list(dataset['id'].values)\n",
        "img_labels = list(dataset['label'].values)\n",
        "\n",
        "print(file_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrsq5uQxVZ8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, os.path\n",
        "\n",
        "val_image_list = []\n",
        "path = \"/content/drive/My Drive/DataSets/HCD_Data/validation\"\n",
        "\n",
        "for f in os.listdir(path):\n",
        "  f = f.replace('.tif', '')\n",
        "  val_image_list.append(f)\n",
        "  \n",
        "print(val_image_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Ic4TYngmAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/DataSets/HCD_Data/train', target_size = (96, 96), batch_size = 32, class_mode = 'binary')\n",
        "validation_set = train_datagen.flow_from_directory('/content/drive/My Drive/DataSets/HCD_Data/validation', target_size = (96, 96), batch_size = 32, class_mode = 'binary')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/DataSets/HCD_Data/test', target_size = (96, 96), batch_size = 32, class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJO4_OPHhgOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "steps_per_epoch = 50,\n",
        "epochs = 10,\n",
        "validation_data = validation_set,\n",
        "validation_steps = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w192bJHRhiF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 3 - Making new predictions\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "count = 0\n",
        "  \n",
        "for x in range(613):\n",
        "  test_image = image.load_img(image_list[x],target_size = (96, 96))\n",
        "  test_image = image.img_to_array(test_image)\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "  result = classifier.predict(test_image)\n",
        "  training_set.class_indices\n",
        "  if result[0][0] >= 0.5:\n",
        "    prediction = 'Atleast one cancerous cell present'\n",
        "    \n",
        "  else:\n",
        "    prediction = 'No cancerous cells present'\n",
        "    count += 1\n",
        "  #print(prediction)\n",
        "  #print(result[0][0])\n",
        "    \n",
        "print(\"correct = \" + str(count))\n",
        "print('acc = ' + str(count/613))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTUrI7W2023v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, os.path\n",
        "\n",
        "image_list = []\n",
        "path = \"/content/drive/My Drive/DataSets/HCD_Data/train/1/\"\n",
        "\n",
        "for f in os.listdir(path):\n",
        "  #f = f.replace('.tif', '')\n",
        "  image_list.append(os.path.join(path, f))\n",
        "  \n",
        "print(len(image_list))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MrUXkm_EDou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code to save a pickel file\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "# now you can save it to a file\n",
        "joblib.dump(classifier, 'HCD_keras.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRZwmjTuvabx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the training images into 2 subfolder depending on the label(0 and 1)\n",
        "for f in range(1500):\n",
        "  \n",
        "  pos = np.where(dataset['id'] == image_list[f])\n",
        "  pos = int(pos[0])\n",
        "  #print(pos)\n",
        "  \n",
        "  current_img = file_names[pos]\n",
        "  current_label = img_labels[pos]\n",
        "  \n",
        "  #print('current_img = ' + current_img)\n",
        "  shutil.move('/content/drive/My Drive/DataSets/HCD_Data/train/1/' + str(current_img) + '.tif', '/content/drive/My Drive/DataSets/HCD_Data/train/' + str(current_label) + '/' + current_img + '.tif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTBWt3cOWzNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in range(500):\n",
        "  \n",
        "  pos = np.where(dataset['id'] == val_image_list[f])\n",
        "  pos = int(pos[0])\n",
        "  \n",
        "  current_img = file_names[pos]\n",
        "  current_label = img_labels[pos]\n",
        "  \n",
        "  shutil.move('/content/drive/My Drive/DataSets/HCD_Data/validation/' + str(current_img) + '.tif', '/content/drive/My Drive/DataSets/HCD_Data/validation/' + str(current_label) + '/' + current_img + '.tif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f79xAdI6EnOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code to find a file\n",
        "import os\n",
        "\n",
        "def find(name, path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if name in files:\n",
        "            return os.path.join(root, name)\n",
        "        \n",
        "find('HCD_keras.pkl', '/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq7OGR78rJuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert any array values or something to strings\n",
        "def to_str(var):\n",
        "    return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]\n",
        "  \n",
        "#Find the row number where a picture with a certain name is located\n",
        "x = np.where(dataset['id'] ==  'pic_name\n",
        "\n",
        "x = int(x[0])\n",
        "\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}